{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction Finetuning\n"
      ],
      "metadata": {
        "id": "nODwmF0MEOQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 구축\n",
        "\n",
        "1. 목적 정의: 먼저, 세부 튜닝을 통해 달성하고자 하는 목표를 명확히 합니다.\n",
        "1. 데이터 수집: 목표에 맞는 데이터를 수집합니다. 이 데이터는 공개 데이터셋일 수도 있고, 사용자가 직접 수집한 데이터일 수도 있습니다.\n",
        "\n",
        "1. 데이터 가공: 수집한 데이터를 모델 훈련에 적합하게 가공합니다. 이 과정에서는 데이터를 정제하고, 필요한 형식으로 변환하는 작업이 포함됩니다."
      ],
      "metadata": {
        "id": "0BGrlf29Eowf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 공개 데이터셋 다운로드"
      ],
      "metadata": {
        "id": "H9r0smmEIAjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets==2.17.0"
      ],
      "metadata": {
        "id": "ilVIo8M0IE1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset = load_dataset(\"royboy0416/ko-alpaca\")\n",
        "\n",
        "# 데이터셋의 구조 확인\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "_Sg9dv0QIWWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "o1basYqSJFys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemma 데이터셋 포맷팅\n",
        "\n",
        "```<start_of_turn>user```<br>\n",
        "```What is Cramer's Rule?<end_of_turn>```<br>\n",
        "```<start_of_turn>model```<br>\n",
        "```Cramer's Rule is ...<end_of_turn>```"
      ],
      "metadata": {
        "id": "aaQbtRTTovBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'prompt' 필드 생성 함수\n",
        "def format_instruction(example):\n",
        "\n",
        "    # 추가 컨텍스트(input 필드)가 있는 경우\n",
        "    if example['input'] and len(example['input']) > 0:\n",
        "        text = f\"\"\"<start_of_turn>user\\n{example[\"instruction\"]}\\n{example[\"input\"]}<end_of_turn>\\n<start_of_turn>model\\n{example[\"output\"]}<end_of_turn>\"\"\"\n",
        "    # input 필드가 없는 경우\n",
        "    else:\n",
        "        text = f\"\"\"<start_of_turn>user\\n{example[\"instruction\"]}<end_of_turn>\\n<start_of_turn>model\\n{example[\"output\"]}<end_of_turn>\"\"\"\n",
        "\n",
        "    return {'prompt': text}\n",
        "\n",
        "# 데이터셋의 prompt 필드를 업데이트\n",
        "dataset = dataset.map(format_instruction)"
      ],
      "metadata": {
        "id": "mMh65FNUKIir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "fs2nTvjMteR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][5]"
      ],
      "metadata": {
        "id": "YOh_8dkHYPMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 로드 및 튜닝:\n",
        "\n",
        "1. 모델 학습: gemma-2b 모델을 로드하고, 준비된 데이터셋을 사용하여 모델을 세부 튜닝합니다. 이 과정에서는 학습률, 에폭 수 등의 파라미터를 조정할 수 있습니다.\n",
        "1. 평가 및 반복: 튜닝된 모델을 평가하고 결과를 확인합니다. 필요에 따라 여러 번 반복하여 모델의 성능을 최적화할 수 있습니다."
      ],
      "metadata": {
        "id": "DtExQUBlEFMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU transformers==4.38.0 accelerate==0.27.1 bitsandbytes==0.42.0 peft==0.8.2 trl==0.7.10"
      ],
      "metadata": {
        "id": "XrefsFXqFM9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "rd1Ya28FujGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import json\n",
        "import time\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "jRjOEOq9JBju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "9Cn_f9eewOs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"google/gemma-2b\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                bnb_4bit_quant_type=\"nf4\",\n",
        "                                bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             quantization_config=bnb_config,\n",
        "                                             device_map={\"\":0})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
      ],
      "metadata": {
        "id": "bZ87WNIPJZLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "bN96zjNf7O25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
        "dataset = dataset['train'].train_test_split(test_size=0.2)\n",
        "dataset"
      ],
      "metadata": {
        "id": "SPJn3dPwwBll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "NRAQtIgVxfG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "FJLdkGrnxmXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(query: str, model, tokenizer):\n",
        "\n",
        "  prompt_template = \"\"\"<start_of_turn>user\n",
        "  {query}\n",
        "  <end_of_turn>\n",
        "  <start_of_turn>model\n",
        "  \"\"\"\n",
        "  prompt = prompt_template.format(query=query)\n",
        "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encodeds.to(\"cuda:0\")\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=256)\n",
        "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "  return decoded\n",
        "\n",
        "# Fine tuning 이전\n",
        "result = get_completion(query=\"건강을 유지하기 위한 세 가지 팁을 알려주세요.\", model=model, tokenizer=tokenizer)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "pO4pjPKdxny-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    target_modules=['o_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'gate_proj'],\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    dataset_text_field=\"prompt\",\n",
        "    peft_config=lora_config,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=10,\n",
        "        max_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=10,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "    ),\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "NTmSRl0Fz4KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning 이후\n",
        "result = get_completion(query=\"건강을 유지하기 위한 세 가지 팁을 알려주세요.\",\n",
        "                        model=trainer.model,\n",
        "                        tokenizer=tokenizer)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "OeygbIZg24Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning 이후\n",
        "result = get_completion(query=\"불면증을 해결하는 방법을 세 가지 알려주세요.\",\n",
        "                        model=trainer.model,\n",
        "                        tokenizer=tokenizer)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "09pIPcLpBuAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 저장"
      ],
      "metadata": {
        "id": "KH9FFSWS2uue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = \"gemma-2b-it-koalpaca-finetuned\"\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "id": "lLGaVpqY2n7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}